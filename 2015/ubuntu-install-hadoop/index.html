<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hugh&#39;Blog › Ubuntu1404下安装Hadoop2.6.0</title>
  <meta name="author" content="Hugh Shen">
  
  <meta name="description" content="安装过程参考1，2，感谢原作者，本文用作记录
单机模式创建用户组和用户并添加权限12sudo addgroup hadoopsudo adduser -ingroup hadoop hadoop">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Ubuntu1404下安装Hadoop2.6.0"/>
  <meta property="og:site_name" content="Hugh&#39;Blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Hugh&#39;Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  
</head>


<body>
  <header id="header"><div class="meta inner">
  <h1><a href="/">Hugh&#39;Blog</a></h1>
  <h2><a href="/"></a></h2>
  <nav id="main-nav">
    <ul>
      
      <li><a href="/">首页</a></li>
      
      <li><a href="/archives">归档</a></li>
      
      <li><a href="/categories">分类</a></li>
      
      <li><a href="/tags">标签</a></li>
      
    </ul>
    <div class="clearfix"></div>
  </nav>
</div>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  <div class="post-content">
    <header>
      
  
    <h1 class="title">Ubuntu1404下安装Hadoop2.6.0</h1>
  

      
      <time datetime="2015-03-29T08:42:24.000Z">发表于2015-03-29</time>
      
    </header>
    <div class="entry">
      
        <p>安装过程参考<a href="http://www.cnblogs.com/kinglau/p/3794433.html" target="_blank" rel="external">1</a>，<a href="http://www.cnblogs.com/kinglau/p/3796164.html" target="_blank" rel="external">2</a>，感谢原<a href="http://home.cnblogs.com/u/kinglau/" target="_blank" rel="external">作者</a>，本文用作记录</p>
<h2 id="单机模式">单机模式</h2><h3 id="创建用户组和用户并添加权限">创建用户组和用户并添加权限</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo addgroup hadoop</span><br><span class="line">sudo adduser -ingroup hadoop hadoop</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>要求密码就输入密码，其他回车就行</p>
<p>编辑 <em>/etc/sudoers</em>，在 <em>root</em> 下面添加 <em>hadoop    ALL=(ALL:ALL) ALL</em></p>
<p>最后使用创建的用户重新登录系统</p>
<h3 id="SSH配置与JAVA_环境">SSH配置与JAVA 环境</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装SSH</span></span><br><span class="line">sudo apt-get install openssh-server</span><br><span class="line"><span class="comment"># 启动SSH服务</span></span><br><span class="line">sudo /etc/init.d/ssh start</span><br><span class="line"><span class="comment"># 设置免密码登录，生成私钥和公钥</span></span><br><span class="line">ssh-keygen -t rsa -P <span class="string">""</span></span><br><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line"><span class="comment"># 登录SSH</span></span><br><span class="line">ssh localhost</span><br><span class="line"><span class="comment"># 退出</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"><span class="comment"># 接下来安装JAVA</span></span><br><span class="line">sudo apt-get install openjdk-<span class="number">7</span>-jdk</span><br><span class="line"><span class="comment"># 查看是否安装成功</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure>
<h3 id="配置Hadoop2-6-0">配置Hadoop2.6.0</h3><p>到<a href="http://mirror.bit.edu.cn/apache/hadoop/common/" target="_blank" rel="external">这里</a>下载 <em>hadoop</em></p>
<p>解压并复制文件夹到想安装的位置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo tar xzf hadoop-<span class="number">2.6</span>.<span class="number">0</span>.tar.gz</span><br><span class="line">sudo mv hadoop-<span class="number">2.6</span>.<span class="number">0</span> /usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="comment"># 修改文件夹读写权限</span></span><br><span class="line">sudo chmod <span class="number">775</span> /usr/<span class="built_in">local</span>/hadoop</span><br></pre></td></tr></table></figure></p>
<p>原文是 <em>774</em>，但是后来 <em>cd</em> 到 <em>hadoop</em> 提示没有权限（不知道什么原因）</p>
<p>设置 <em>JAVA_HOME</em> 环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看JAVA安装路径</span></span><br><span class="line">update-alternatives - -config java</span><br></pre></td></tr></table></figure></p>
<p>显示 <em>/usr/lib/jvm/java-7-openjdk-i386/jre/bin/java</em> ，取其中的 <em>/usr/lib/jvm/java-7-openjdk-i386</em></p>
<p>修改 <em>~/.bashrc</em> 文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HADOOP VARIABLES START</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-<span class="number">7</span>-openjdk-i386</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_INSTALL</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_INSTALL</span>/sbin</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_INSTALL</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_INSTALL</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_INSTALL</span>/lib"</span></span><br><span class="line"><span class="comment">#HADOOP VARIABLES END</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使环境变量生效。</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>编辑 <em>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</em>，找到 <em>JAVA_HOME</em> 变量修改为<br><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export <span class="constant">JAVA_HOME</span>=<span class="regexp">/usr/lib</span><span class="regexp">/jvm/java</span>-<span class="number">7</span>-openjdk-amd64</span><br></pre></td></tr></table></figure></p>
<h3 id="WordCount测试">WordCount测试</h3><p>单机模式安装完成，下面通过执行 <em>hadoop</em> 自带实例 <em>WordCount</em> 验证是否安装成功<br><em>/usr/local/hadoop</em> 路径下创建 <em>input</em> 文件夹，并添加文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir input</span><br><span class="line">sudo cp README.txt input</span><br></pre></td></tr></table></figure></p>
<p>明明已经给 <em>hadoop</em>添加权限了，但是还是需要 <em>sudo …</em></p>
<p>执行 <em>WordCount</em>，注意 <em>hadoop</em> 的版本要正确，这里是 <em>2.6.0</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop jar share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-<span class="number">2.6</span>.<span class="number">0</span>-sources.jar org.apache.hadoop.examples.WordCount input output</span><br><span class="line"><span class="comment"># 执行完之后查看结果</span></span><br><span class="line">cat output/*</span><br></pre></td></tr></table></figure></p>
<h2 id="伪分布模式">伪分布模式</h2><h3 id="配置xml文件">配置xml文件</h3><p>在 <em>/usr/local/hadoop/etc/hadoop/</em> 修改以下文件，找到<code>&lt;configuration&gt;&lt;/configuration&gt;</code>并增加内容</p>
<p><em>core-site.xml</em> 包含了 <em>hadoop</em> 启动时的配置信息<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>fs.default.name<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><em>yarn-site.xml</em> 包含了 <em>MapReduce</em> 启动时的配置信息<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn<span class="class">.nodemanager</span><span class="class">.aux-services</span>&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn<span class="class">.nodemanager</span><span class="class">.aux-services</span><span class="class">.mapreduce</span><span class="class">.shuffle</span><span class="class">.class</span>&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;org<span class="class">.apache</span><span class="class">.hadoop</span><span class="class">.mapred</span><span class="class">.ShuffleHandler</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p><em>mapred-site.xml</em> 用于指定 <em>MapReduce</em> 使用的框架<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line">cp mapred-site.xml.template mapred-site.xml</span><br></pre></td></tr></table></figure></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><em>hdfs-site.xml</em> 用来配置集群中每台主机都可用，指定主机上作为 <em>namenode</em> 和 <em>datanode</em>的目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line">sudo mkdir hdfs</span><br><span class="line">sduo mkdir hdfs/name</span><br><span class="line">sduo mkdir hdfs/data</span><br></pre></td></tr></table></figure></p>
<p>可以在别的路径下创建 <em>name</em> 和 <em>data</em> 文件夹，名称也可以与不同，但是需要和 <em>hdfs-site.xml</em> 中的配置一致<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;<span class="keyword">property</span>&gt;</span><br><span class="line">        &lt;<span class="property">name</span>&gt;dfs.replication&lt;/<span class="property">name</span>&gt;</span><br><span class="line">        &lt;value&gt;<span class="number">1</span>&lt;/value&gt;</span><br><span class="line">&lt;/<span class="keyword">property</span>&gt;</span><br><span class="line">&lt;<span class="keyword">property</span>&gt;</span><br><span class="line">        &lt;<span class="property">name</span>&gt;dfs.namenode.<span class="property">name</span>.dir&lt;/<span class="property">name</span>&gt;</span><br><span class="line">        &lt;value&gt;<span class="type">file</span>:/usr/<span class="keyword">local</span>/hadoop/hdfs/<span class="property">name</span>&lt;/value&gt;</span><br><span class="line">&lt;/<span class="keyword">property</span>&gt;</span><br><span class="line">&lt;<span class="keyword">property</span>&gt;</span><br><span class="line">        &lt;<span class="property">name</span>&gt;dfs.datanode.data.dir&lt;/<span class="property">name</span>&gt;</span><br><span class="line">        &lt;value&gt;<span class="type">file</span>:/usr/<span class="keyword">local</span>/hadoop/hdfs/data&lt;/value&gt;</span><br><span class="line">&lt;/<span class="keyword">property</span>&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="启动Hadoop">启动Hadoop</h3><p>首先格式化 <em>hdfs</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line"><span class="comment"># 原文没有这个</span></span><br><span class="line">hdfs datanode -format</span><br></pre></td></tr></table></figure></p>
<p>只需要执行一次即可，如果在 <em>hadoop</em> 已经使用后再次执行，会清除掉 <em>hdfs</em> 上的所有数据</p>
<p>经过上文所描述配置和操作后，下面就可以启动这个单节点的集群，注意在 <em>/usr/local/hadoop/etc/hadoop</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br><span class="line"><span class="comment"># 执行该命令时，如果有yes /no提示，输入yes，回车即可。</span></span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"><span class="comment"># jps命令，可以查看Hadoop相关的进程，一般有NameNode,SecondaryNameNode,DataNode,JPS,NodeManager</span></span><br><span class="line">jps</span><br></pre></td></tr></table></figure></p>
<p>中途如果出现 <em>root@localhost’s password</em>，可以把 <em>hadoop</em> 文件夹的所有者与用户修改为 <em>hadoop</em><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown hadoop:hadoop /usr/<span class="built_in">local</span>/hadoop</span><br></pre></td></tr></table></figure></p>
<p>在浏览器中输入 <em>localhost:50070</em>，会看到 <em>hdfs</em> 管理页面；<em>localhost:8088</em>，会看到 <em>hadoop</em> 进程管理页面</p>
<h3 id="WordCount验证">WordCount验证</h3><p><em>/usr/local/hadoop/etc/hadoop</em> 下运行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dfs上创建input目录</span></span><br><span class="line">bin/hadoop fs -mkdir -p input</span><br><span class="line"><span class="comment"># 把hadoop目录下的README.txt拷贝到dfs新建的input里</span></span><br><span class="line">hadoop fs -copyFromLocal README.txt input</span><br><span class="line"><span class="comment"># 运行WordCount</span></span><br><span class="line">hadoop jar share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-<span class="number">2.6</span>.<span class="number">0</span>-sources.jar org.apache.hadoop.examples.WordCount input output</span><br><span class="line"><span class="comment"># 查看单词统计结果</span></span><br><span class="line">hadoop fs -cat output/*</span><br></pre></td></tr></table></figure></p>
<hr>
<p><strong>虽然配置好了 <em>hadoop</em>，但是接下来还有很多要学习的，，，最后再次感谢原<a href="http://home.cnblogs.com/u/kinglau/" target="_blank" rel="external">作者</a></strong></p>

      
    </div>
    
    <footer>
      <div class="alignleft">
      
  
  <div class="categories">
    <a href="/categories/study/">学习</a>
  </div>

      
  
  <div class="tags">
    <a href="/tags/Hadoop/">Hadoop</a>, <a href="/tags/Ubuntu/">Ubuntu</a>
  </div>

      </div>
      <div class="clearfix"></div>
    </footer>
    
  </div>
</article>


<section id="comment">
  
</section>

</div></div>
    <div class="clearfix"></div>
  </div>
  <footer id="footer"><div class="inner"><div class="alignleft">
  <p>
  
    &copy; 2015 Hugh Shen
  
  </p>
  <p>
    <a href="http://github.com/willerce/hexo-theme-noderce">Noderce</a> Theme By <a href="http://willerce.com" >willerce</a>
  </p>

</div>
<div class="clearfix"></div></div></footer>
  <script type="text/javascript">

</script>

</body>
</html>
